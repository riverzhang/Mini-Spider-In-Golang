[spider]
# spider seed file
# 种子文件路径
urlListFile = ../data/seed.data

# spider output dir
# 抓取结果存储目录 
outputDirectory = ../output/

# spider max crawler deep
# 最大抓取深度(种子为0级)
maxDepth = 1

# spider crawler interval
# 抓取间隔. 单位: 秒 
crawlInterval = 1

# spider crawler timeout
# 抓取超时. 单位: 秒 
crawlTimeout = 1

# spider crawler target pattern, use by default paser : regexp_parser.go.
# you can DIY your parser.
# 需要存储的目标网页URL pattern(正则表达式), 供默认的解析器regexp_parser.go使用。
# 你可以按照自己的需求，实现 parser，实现定下抓取，不需要考虑targetUrl设置。
targetUrl = .*.(htm|html)$

# num of routine
# 抓取routine数 
threadCount = 10